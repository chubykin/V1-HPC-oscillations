{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context('poster')\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "# import Python3_OpenOE_AC_map_functions_v1_08_30s as oem\n",
    "import mz_LFP_functions as mz_LFP\n",
    "\n",
    "import matplotlib.animation as ani #this was a good idea that I didn't want to spend time on right now\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load some necessary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310.0 200.0 90.0 150.0\n"
     ]
    }
   ],
   "source": [
    "insert_depth = 3100  #change this as appropriate\n",
    "\n",
    "sp_bw_ch = 20/2\n",
    "\n",
    "surface_ch = np.round(insert_depth/sp_bw_ch)\n",
    "V1_hip_ch = np.round((insert_depth-1100)/sp_bw_ch)\n",
    "Hip_thal_ch = np.round((insert_depth-1000-1200)/sp_bw_ch)\n",
    "\n",
    "CA1_DG_ch = np.round((insert_depth-1000-600)/sp_bw_ch)\n",
    "\n",
    "print(surface_ch, V1_hip_ch, Hip_thal_ch, CA1_DG_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_tr = 7350 #this is based on the shortest #samples in a trial\n",
    "sr = 2500\n",
    "n_chan = 384\n",
    "rec_length = 3.0 #how long is the arduino triggered?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For multiple mice\n",
    "Requires a __`user input`__ to choose the scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario (pre, post, novel): novel\n"
     ]
    }
   ],
   "source": [
    "data_choice = input('Scenario (pre, post, novel): ')\n",
    "\n",
    "if data_choice == 'pre':\n",
    "    start_path_ls=glob.glob(r\"G://\"+'pre*')     # pre-training to the visual stim\n",
    "    total_rec = 34\n",
    "elif data_choice == 'post':\n",
    "    start_path_ls=glob.glob(r\"G://\"+'post*')     # post-training to the visual stim\n",
    "    total_rec = 34\n",
    "elif data_choice == 'novel':\n",
    "    start_path_ls=glob.glob(r\"G://\"+'novel*')     # novel stimulus\n",
    "    total_rec = 54\n",
    "else:\n",
    "    raise Exception('Input is not one of the options (pre, post, novel)')\n",
    "\n",
    "\n",
    "end_path = r\"\\continuous\\Neuropix-PXI-100.1\\continuous.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['CC082263HP1',\n",
       " 'CC082263HP2',\n",
       " 'CC082263HP3',\n",
       " 'CC084621HP1',\n",
       " 'CC084621HP2',\n",
       " 'CC067489HP2',\n",
       " 'CC067489HP3',\n",
       " 'CC082260HP2',\n",
       " 'CC082260HP3',\n",
       " 'CC082260HP4']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldatals=[]\n",
    "et_ls = []\n",
    "for start_path in start_path_ls:\n",
    "    ls = []\n",
    "    et = start_path.split('\\\\')[-1].split('_')[1]\n",
    "    \n",
    "    for i in range(6, total_rec): # remember, you have to exclude the first short TTL signal trials\n",
    "        exp_rec_path = rf\"\\experiment1\\recording{i}\"\n",
    "        fileName = start_path + exp_rec_path + end_path\n",
    "        data = np.memmap(fileName, dtype='int16', mode='c')\n",
    "        data2 = data.reshape(-1, n_chan)\n",
    "        ls.append(data2[:samples_tr, 0:384])\n",
    "        \n",
    "    alldatals.append(ls)\n",
    "    et_ls.append(et)\n",
    "\n",
    "# alldatals: num_mice x num_trials x num_samples x num_ch\n",
    "num_mice = len(et_ls)\n",
    "print(num_mice)\n",
    "et_ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the lists into CAR filtered arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.linspace(0, samples_tr/sr, samples_tr)\n",
    "scale_factor = 0.195\n",
    "time_arr = [0,0.5,1,1.5,2,2.5]\n",
    "time_plot = [i*sr for i in time_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses \"applyCAR\" and \"notch_filt\" functions\n",
    "def create_novel_arr(alldatals):\n",
    "    novel_ls=[]\n",
    "    for i in range(len(alldatals)):\n",
    "        tmp2 = np.mean(alldatals[i], axis = 0)           # getting the mean traces over all trials\n",
    "        tmp2 = tmp2.T\n",
    "        filt_tmp2 = []\n",
    "        for ch in range(tmp2.shape[0]):\n",
    "            ch_data = tmp2[ch,:]\n",
    "            ch_notc_data = mz_LFP.notch_filt(ch_data)\n",
    "            filt_tmp2.append(ch_notc_data)\n",
    "        filt_tmp2 = np.array(filt_tmp2)\n",
    "        CARfilt_tmp2 = mz_LFP.applyCAR(filt_tmp2, pr=0)\n",
    "        scaled_CARfilt_tmp2 = CARfilt_tmp2*scale_factor\n",
    "        novel_ls.append(scaled_CARfilt_tmp2)\n",
    "        print('Loaded {0}'.format(i))\n",
    "    final_arr = np.array(novel_ls)\n",
    "    return final_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses \"applyCAR\" and \"notch_filt\" functions\n",
    "def create_all_arr(alldatals):\n",
    "    novel_ls=[]\n",
    "    for i in range(len(alldatals)):\n",
    "        tmp2 = alldatals[i]  # getting the individual trial\n",
    "        tmp3_ls = []\n",
    "        for ii in range(len(tmp2)):\n",
    "            tmp3 = tmp2[ii]\n",
    "            tmp3 = tmp3.T\n",
    "            filt_tmp3 = []\n",
    "            for ch in range(tmp3.shape[0]):\n",
    "                ch_data = tmp3[ch,:]\n",
    "                ch_notc_data = mz_LFP.notch_filt(ch_data)\n",
    "                filt_tmp3.append(ch_notc_data)\n",
    "            filt_tmp3 = np.array(filt_tmp3)\n",
    "            CARfilt_tmp3 = mz_LFP.applyCAR(filt_tmp3, pr=0)\n",
    "            scaled_CARfilt_tmp3 = CARfilt_tmp3*scale_factor\n",
    "            tmp3_ls.append(scaled_CARfilt_tmp3)\n",
    "        novel_ls.append(tmp3_ls)\n",
    "        print('Loaded {0}'.format(i))\n",
    "    final_arr = np.array(novel_ls)\n",
    "    return final_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alldatals) # # mice x # trials x # samples x # channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0\n",
      "Loaded 1\n",
      "Loaded 2\n",
      "Loaded 3\n",
      "Loaded 4\n",
      "Loaded 5\n",
      "Loaded 6\n",
      "Loaded 7\n",
      "Loaded 8\n",
      "Loaded 9\n"
     ]
    }
   ],
   "source": [
    "# all_arr = create_novel_arr(alldatals) #makes the averaged np.array with mice/channels/samples\n",
    "all_arr = create_all_arr(alldatals) #makes a larger array with all mice/trials/channels/samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 48, 384, 7350)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the LFP arrays and CC_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "arr_save_path = r\"D:\\LFPs\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_choice == 'pre':\n",
    "    fn1 = r\"pre_alltr\"\n",
    "    out1 = arr_save_path + \"\\\\\" + fn1\n",
    "    np.save(out1, all_arr)         # saving pre array\n",
    "    pkl_fn = r\"pre_alltr_et_ls\"\n",
    "elif data_choice == 'post':\n",
    "    fn1 = r\"post_alltr\"\n",
    "    out1 = arr_save_path + \"\\\\\" + fn1\n",
    "    np.save(out1, all_arr)         # saving post array\n",
    "    pkl_fn = r\"post_alltr_et_ls\"\n",
    "elif data_choice == 'novel':\n",
    "    fn1 = r\"novel_alltr\"\n",
    "    out1 = arr_save_path + \"\\\\\" + fn1\n",
    "    np.save(out1, all_arr)         # saving novel array\n",
    "    pkl_fn = r\"novel_alltr_et_ls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_out = arr_save_path + \"\\\\\" + pkl_fn\n",
    "\n",
    "open_file = open(pkl_out, \"wb\")\n",
    "pickle.dump(et_ls, open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
