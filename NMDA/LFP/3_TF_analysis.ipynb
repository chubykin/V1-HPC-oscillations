{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# # For TF analysis\n",
    "import scipy.fftpack\n",
    "from scipy.fftpack import fft, ifft\n",
    "from scipy import signal\n",
    "\n",
    "sns.set_context('poster')\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "# import Python3_OpenOE_AC_map_functions_v1_08_30s as oem\n",
    "import mz_LFP_functions as mz_LFP\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for publication quality plots\n",
    "def set_pub_plots(pal=sns.blend_palette([\"gray\",\"crimson\", 'cyan', 'magenta', 'purple'  ],5)):\n",
    "    sns.set_style(\"white\")\n",
    "    sns.set_palette(pal)\n",
    "    sns.set_context(\"poster\", font_scale=1.5, rc={\"lines.linewidth\": 2.5, \"axes.linewidth\":2.5, 'figure.facecolor': 'white'}) \n",
    "    sns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\n",
    "    # optional, makes markers bigger, too, axes.linewidth doesn't seem to work\n",
    "    plt.rcParams['axes.linewidth'] = 2.5\n",
    "\n",
    "rc_pub={'font.size': 25, 'axes.labelsize': 25, 'legend.fontsize': 25.0, \n",
    "    'axes.titlesize': 25, 'xtick.labelsize': 25, 'ytick.labelsize': 25, \n",
    "    #'axes.color_cycle':pal, # image.cmap - rewritesd the default colormap\n",
    "    'axes.linewidth':2.5, 'lines.linewidth': 2.5,\n",
    "    'xtick.color': 'black', 'ytick.color': 'black', 'axes.edgecolor': 'black','axes.labelcolor':'black','text.color':'black'}\n",
    "# to restore the defaults, call plt.rcdefaults() \n",
    "\n",
    "#set_pub_bargraphs()\n",
    "set_pub_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pal=sns.blend_palette(['black','royalblue'],2)\n",
    "sns.palplot(pal)\n",
    "sns.set_palette(pal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load some necessary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_depth = 1000  #change this as appropriate\n",
    "\n",
    "sp_bw_ch = 20/2\n",
    "samples_tr = 7350 #this is based on the shortest #samples in a trial\n",
    "sr = 2500\n",
    "n_chan = 384\n",
    "rec_length = 3.0 #how long is the arduino triggered?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, load in the .npy arrays and CC_ls\n",
    "These were creaded and saved using the \"1_saving_LFP_arrays\" jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pre_arr = np.load(r\"D:\\mz_Data\\saved_dfs\\HPC_nmda\\lfp_npy\\pre_all.npy\")\n",
    "all_post_arr = np.load(r\"D:\\mz_Data\\saved_dfs\\HPC_nmda\\lfp_npy\\post_all.npy\")\n",
    "all_novel_arr = np.load(r\"D:\\mz_Data\\saved_dfs\\HPC_nmda\\lfp_npy\\novel_all.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = r\"D:\\mz_Data\\saved_dfs\\HPC_nmda\\lfp_npy\\pre_et_ls\"\n",
    "\n",
    "open_file = open(pkl_file, \"rb\")\n",
    "et_ls_pre = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "len(et_ls_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = r\"D:\\mz_Data\\saved_dfs\\HPC_nmda\\lfp_npy\\post_et_ls\"\n",
    "\n",
    "open_file = open(pkl_file, \"rb\")\n",
    "et_ls_post = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "len(et_ls_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = r\"D:\\mz_Data\\saved_dfs\\HPC_nmda\\lfp_npy\\novel_et_ls\"\n",
    "\n",
    "open_file = open(pkl_file, \"rb\")\n",
    "et_ls_novel = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "len(et_ls_novel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Frequency plots\n",
    "### First, make some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regroup(all_array, et_ls, show=1):\n",
    "    nmda = []\n",
    "    sham = []\n",
    "    for i in range(all_array.shape[0]):\n",
    "        nmda_ls = ['et1710', 'et1700', 'et1570', 'et1520', 'et171', 'et170', 'et157', 'et152']\n",
    "        if et_ls[i] in nmda_ls:\n",
    "            nmda.append(all_array[i])\n",
    "        else:\n",
    "            sham.append(all_array[i])\n",
    "\n",
    "    tf_sham_arr = np.array(sham)\n",
    "    tf_nmda_arr = np.array(nmda)\n",
    "    \n",
    "    if show == 1:\n",
    "        print(tf_sham_arr.shape)\n",
    "        print(tf_nmda_arr.shape)\n",
    "    \n",
    "    return tf_sham_arr, tf_nmda_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tf_data(group_arr):\n",
    "    chs_ls = []\n",
    "    for ii in range(group_arr.shape[0]):\n",
    "        V1_region = group_arr[ii][0:100,:]\n",
    "        min_ch = np.where(V1_region == np.amin(V1_region))\n",
    "        min_ch2 = min_ch[0][0] + 0\n",
    "        chs_ls.append(group_arr[ii][min_ch2,:])\n",
    "        \n",
    "    tf_plot = np.array(chs_ls)\n",
    "    tf_plot_mean = np.mean(tf_plot, axis=0)\n",
    "    tf_plot_mean = np.reshape(tf_plot_mean,(1,len(tf_plot_mean)))\n",
    "    \n",
    "    return tf_plot, tf_plot_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second, reestablish the A and B groups\n",
    "These are 3d arrays with the following dimensions:\n",
    "mice x ch x samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sham_pre, nmda_pre = regroup(all_pre_arr, et_ls_pre, show=0)\n",
    "sham_post, nmda_post = regroup(all_post_arr, et_ls_post, show=0)\n",
    "sham_novel, nmda_novel = regroup(all_novel_arr, et_ls_novel, show=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third, apply the functions to find the strongest ch averaged across all mice\n",
    "This differs from a previous cell commented out because it iterates through each mouse and find the strongest channel, which is appended to a list. The mean of this list is then used to plot the TF.\n",
    "\n",
    "The important part is that the strongest channel from each mouse is used and not the overall strongest channel after averaging.\n",
    "- Previous: average all recordings, then find strongest response\n",
    "- Current: find strongest response for each mouse, then average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_tf_sham, mean_pre_sham = make_tf_data(sham_pre)\n",
    "pre_tf_nmda, mean_pre_nmda = make_tf_data(nmda_pre)\n",
    "\n",
    "post_tf_sham, mean_post_sham = make_tf_data(sham_post)\n",
    "post_tf_nmda, mean_post_nmda = make_tf_data(nmda_post)\n",
    "\n",
    "novel_tf_sham, mean_novel_sham = make_tf_data(sham_novel)\n",
    "novel_tf_nmda, mean_novel_nmda = make_tf_data(nmda_novel)\n",
    "\n",
    "# this is just printing an example shape to make sure it worked correctly\n",
    "print('Example dimension check! \\nShould go from (n,7350) to (1,7350)')\n",
    "print(pre_tf_sham.shape)\n",
    "print(mean_pre_sham.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth, plot the individual TF heatmaps for each group\n",
    "The cell below requires a _`user input`_ for the scenario you want to look at!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rew_selection = input('Scenario (pre, post, novel): ')\n",
    "\n",
    "if rew_selection == 'pre':\n",
    "    groupA_plot = mean_pre_sham\n",
    "    groupB_plot = mean_pre_nmda\n",
    "    plt_titleA = 'sham - pre'\n",
    "    plt_titleB = 'nmda - pre'\n",
    "    fnA = \"pre_sham_heat.pdf\"\n",
    "    fnB = \"pre_nmda_heat.pdf\"\n",
    "elif rew_selection == 'post':\n",
    "    groupA_plot = mean_post_sham\n",
    "    groupB_plot = mean_post_nmda\n",
    "    plt_titleA = 'sham - post'\n",
    "    plt_titleB = 'nmda - post'\n",
    "    fnA = \"post_sham_heat.pdf\"\n",
    "    fnB = \"post_nmda_heat.pdf\"\n",
    "elif rew_selection == 'novel':\n",
    "    groupA_plot = mean_novel_sham\n",
    "    groupB_plot = mean_novel_nmda\n",
    "    plt_titleA = 'sham - novel'\n",
    "    plt_titleB = 'nmda - novel'\n",
    "    fnA = \"novel_sham_heat.pdf\"\n",
    "    fnB = \"novel_nmda_heat.pdf\"\n",
    "else:\n",
    "    raise Exception('Input is not one of the 3 options')\n",
    "\n",
    "    \n",
    "f_path_start = r\"C:\\Users\\AChub_Lab\\Desktop\\tmp_nmda\\tf\" #change this file destination!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax1 = plt.subplots()\n",
    "tf_A, time_A, frex_A, tf3d_A = mz_LFP.tf_cmw(ax=ax1, df_res=groupA_plot)\n",
    "f,ax1.set_title(plt_titleA)\n",
    "sns.despine()\n",
    "\n",
    "# Change the end of this next line with a new file name!!\n",
    "# f_path = f_path_start + '\\\\' + fnA\n",
    "# plt.savefig(f_path, transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax2 = plt.subplots()\n",
    "tf_B, time_B, frex_B, tf3d_B = mz_LFP.tf_cmw(ax=ax2,df_res=groupB_plot)\n",
    "ax2.set_title(plt_titleB)\n",
    "sns.despine()\n",
    "\n",
    "# Change the end of this next line with a new file name!!\n",
    "# f_path = f_path_start + '\\\\' + fnB\n",
    "# plt.savefig(f_path, transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fifth, rerun the TF code to extract the freq. band values\n",
    "I have to rerun it on each mouse to get the confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_window = [0.7,2.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pre_sham_df = mz_LFP.TF_band_values(pre_tf_sham, time_window)\n",
    "pre_nmda_df = mz_LFP.TF_band_values(pre_tf_nmda, time_window)\n",
    "\n",
    "post_sham_df = mz_LFP.TF_band_values(post_tf_sham, time_window)\n",
    "post_nmda_df = mz_LFP.TF_band_values(post_tf_nmda, time_window)\n",
    "\n",
    "novel_sham_df = mz_LFP.TF_band_values(novel_tf_sham, time_window)\n",
    "novel_nmda_df = mz_LFP.TF_band_values(novel_tf_nmda, time_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sixth, combine the two group dfs, maintaining an ID for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_sham_df['group'] = 'sham'\n",
    "pre_sham_df['stim_id'] = 'pre'\n",
    "pre_nmda_df['group'] = 'nmda'\n",
    "pre_nmda_df['stim_id'] = 'pre'\n",
    "\n",
    "post_sham_df['group'] = 'sham'\n",
    "post_sham_df['stim_id'] = 'post'\n",
    "post_nmda_df['group'] = 'nmda'\n",
    "post_nmda_df['stim_id'] = 'post'\n",
    "\n",
    "novel_sham_df['group'] = 'sham'\n",
    "novel_sham_df['stim_id'] = 'novel'\n",
    "novel_nmda_df['group'] = 'nmda'\n",
    "novel_nmda_df['stim_id'] = 'novel'\n",
    "\n",
    "overall_tf = pd.concat([pre_sham_df, pre_nmda_df, post_sham_df, post_nmda_df, novel_sham_df, novel_nmda_df])\n",
    "overall_tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(overall_tf.group.unique())\n",
    "print(overall_tf.stim_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seventh, plot the frequency band values\n",
    "separated out from each other by the different groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_plot1 = overall_tf[overall_tf['stim_id'] == 'pre']\n",
    "plt_title1 = 'Pre-training'\n",
    "TF_plot2 = overall_tf[overall_tf['stim_id'] == 'post']\n",
    "plt_title2 = 'Post-training'\n",
    "TF_plot3 = overall_tf[overall_tf['stim_id'] == 'novel']\n",
    "plt_title3 = 'Novel'\n",
    "\n",
    "plt_yticks = [-4,0,4,8,12,16,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the barplot of the T-F plot\n",
    "\n",
    "g = sns.catplot(x='variable', y='value', data=overall_tf, kind = 'bar', col='stim_id',\n",
    "                hue='group', hue_order=['sham','nmda'],\n",
    "                legend=False,\n",
    "                height = 6, aspect=1.2,\n",
    "                order=['4-8Hz', '8-12Hz', '12-30Hz', '30-40Hz','50-70Hz','30-70Hz'], \n",
    "                ci=68)\n",
    "\n",
    "g.set_xticklabels(['4-8Hz', '8-12Hz', '12-30Hz', '30-40Hz','50-70Hz','30-70Hz'],\n",
    "                           rotation=40, fontsize=20)\n",
    "\n",
    "plt.xlabel('')\n",
    "plt.yticks(plt_yticks)\n",
    "plt.ylabel('Power (dB)')\n",
    "plt.legend(loc=\"upper right\")\n",
    "sns.despine()\n",
    "\n",
    "# Change the end of this next line with a new file name!!\n",
    "# plt.savefig(r\"C:\\Users\\AChub_Lab\\Desktop\\tmp_nmda\\tf\\tf_bar.pdf\", transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eighth, find the stats for the above plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF_stats(df):\n",
    "    tf_groups = np.array(['4-8Hz','8-12Hz','12-30Hz','30-40Hz','50-70Hz','30-70Hz'])\n",
    "    stat_result = []\n",
    "    for ii in tf_groups:\n",
    "        foo_A = df[(df['variable'] == ii) & (df['group'] == 'sham')].value.values\n",
    "        foo_B = df[(df['variable'] == ii) & (df['group'] == 'nmda')].value.values\n",
    "        U, p = stats.mannwhitneyu(foo_A, foo_B)\n",
    "\n",
    "        stat_result.append(ii)\n",
    "        stat_result.append([U,p])\n",
    "\n",
    "    return stat_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_TF_stats = TF_stats(TF_plot1)\n",
    "post_TF_stats = TF_stats(TF_plot2)\n",
    "novel_TF_stats = TF_stats(TF_plot3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plt_title1)\n",
    "print(pre_TF_stats)\n",
    "print(plt_title2)\n",
    "print(post_TF_stats)\n",
    "print(plt_title3)\n",
    "print(novel_TF_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
