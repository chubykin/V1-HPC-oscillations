{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.fftpack import fft, ifft\n",
    "\n",
    "import pingouin as pg\n",
    "\n",
    "from glob import glob\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('poster')\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "# for publication quality plots\n",
    "def set_pub_plots(pal=sns.blend_palette([\"gray\",\"crimson\", 'cyan', 'magenta', 'purple'  ],5)):\n",
    "    sns.set_style(\"white\")\n",
    "    sns.set_palette(pal)\n",
    "    sns.set_context(\"poster\", font_scale=1.5, rc={\"lines.linewidth\": 2.5, \"axes.linewidth\":2.5, 'figure.facecolor': 'white'}) \n",
    "    sns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\n",
    "    plt.rcParams['axes.linewidth'] = 2.5\n",
    "\n",
    "rc_pub={'font.size': 25, 'axes.labelsize': 25, 'legend.fontsize': 25.0, \n",
    "    'axes.titlesize': 25, 'xtick.labelsize': 25, 'ytick.labelsize': 25, \n",
    "    'axes.linewidth':2.5, 'lines.linewidth': 2.5,\n",
    "    'xtick.color': 'black', 'ytick.color': 'black', 'axes.edgecolor': 'black','axes.labelcolor':'black','text.color':'black'}\n",
    "# to restore the defaults, call plt.rcdefaults() \n",
    "\n",
    "set_pub_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pal=sns.blend_palette(['black','royalblue'],2)\n",
    "sns.palplot(pal)\n",
    "sns.set_palette(pal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_plv(x, y, num_samples=7350, \n",
    "             Sampling_Rate=2500,\n",
    "             base_idx = [0, 400],\n",
    "             min_freq = 2,\n",
    "             max_freq = 90,\n",
    "             num_frex = 40,\n",
    "             range_cycles = [3, 10]\n",
    "            ):\n",
    "    \n",
    "    #frequencies vector\n",
    "    frex = np.logspace(np.log10(min_freq),np.log10(max_freq),num_frex)\n",
    "    time = np.linspace(0, num_samples, int(num_samples) )\n",
    "\n",
    "    #wavelet parameters\n",
    "    s = np.divide(np.logspace(np.log10(range_cycles[0]), np.log10(range_cycles[-1]), num_frex), 2*np.pi*frex)\n",
    "    wavtime = np.linspace(-1, 1, 2*int(Sampling_Rate)+1)\n",
    "    half_wave = (len(wavtime)-1)/2\n",
    "\n",
    "    #FFT parameters\n",
    "    nWave = len(wavtime)\n",
    "\n",
    "    num_trials= x[:20].shape[0]\n",
    "    nData = num_trials * num_samples\n",
    "    nConv = [nWave+nData-1, nWave+nData-1 ,  nWave+num_samples-1 ]\n",
    "\n",
    "    dataX = {}\n",
    "    dataY = {}\n",
    "#             #FFT of total data\n",
    "    dataX[0] = fft( x[:20].flatten(), nConv[0])\n",
    "    dataY[0] = fft( y[:20].flatten(), nConv[0])\n",
    "\n",
    "    tf = np.zeros((len(frex), num_samples) )\n",
    "    phd = np.zeros((len(frex), num_samples) )\n",
    "    \n",
    "    #main loop\n",
    "    for fi in range(len(frex)):\n",
    "        # create wavelet and get its FFT\n",
    "        # the wavelet doesn't change on each trial...\n",
    "        wavelet  = np.exp(2*1j*np.pi*frex[fi]*wavtime) * np.exp(-wavtime**2/(2*s[fi]**2))    \n",
    "\n",
    "        # need separate FFT \n",
    "        waveletX = fft(wavelet,nConv[0])\n",
    "        waveletX = waveletX / max(waveletX)\n",
    "\n",
    "        # notice that the fft_EEG cell changes on each iteration\n",
    "        a_sig = ifft(waveletX*dataX[0],nConv[0])\n",
    "        b_sig = ifft(waveletX*dataY[0],nConv[0])\n",
    "\n",
    "        a_sig = a_sig[int(half_wave): int(len(a_sig)-half_wave)]\n",
    "        b_sig = b_sig[int(half_wave): int(len(b_sig)-half_wave)]\n",
    "        aphase = (np.angle(a_sig)+2*np.pi)%(2*np.pi)\n",
    "        bphase = (np.angle(b_sig)+2*np.pi)%(2*np.pi)\n",
    "        phased = aphase - bphase\n",
    "#         phd[fi,:]=(phased.reshape(-1,2000))\n",
    "        phd[fi,:]=pg.circ_mean(((phased.reshape(-1,num_samples)+2*np.pi)%(2*np.pi)))\n",
    "        tf[fi,:]=np.abs(np.exp(1j*phased).reshape(-1,num_samples).sum(axis=0))/(phased.reshape(-1,num_samples).shape[0])\n",
    "        \n",
    "    return tf, phd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, load in the .npy arrays and CC_ls\n",
    "These were creaded and saved using the \"1_saving_LFP_arrays\" jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pre_arr = np.load(r\"D:\\mz_Data\\saved_dfs\\HPC_nmda\\lfp_npy\\pre_all_trials.npy\")\n",
    "all_post_arr = np.load(r\"D:\\mz_Data\\saved_dfs\\HPC_nmda\\lfp_npy\\post_all_trials.npy\")\n",
    "all_novel_arr = np.load(r\"D:\\mz_Data\\saved_dfs\\HPC_nmda\\lfp_npy\\novel_all_trials.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = r\"D:\\mz_Data\\saved_dfs\\HPC_nmda\\lfp_npy\\pre_et_ls\"\n",
    "\n",
    "open_file = open(pkl_file, \"rb\")\n",
    "et_ls_pre = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "len(et_ls_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = r\"D:\\mz_Data\\saved_dfs\\HPC_nmda\\lfp_npy\\post_et_ls\"\n",
    "\n",
    "open_file = open(pkl_file, \"rb\")\n",
    "et_ls_post = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "len(et_ls_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = r\"D:\\mz_Data\\saved_dfs\\HPC_nmda\\lfp_npy\\novel_et_ls\"\n",
    "\n",
    "open_file = open(pkl_file, \"rb\")\n",
    "et_ls_novel = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "len(et_ls_novel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_mice_groups(data_array, et_ls):\n",
    "    nmda = []\n",
    "    sham = []\n",
    "    for i in range(data_array.shape[0]):\n",
    "        nmda_ls = ['et1710', 'et1700', 'et1570', 'et1520', 'et171', 'et170', 'et157', 'et152']\n",
    "        if et_ls[i] in nmda_ls:\n",
    "            nmda.append(data_array[i])\n",
    "        else:\n",
    "            sham.append(data_array[i])\n",
    "\n",
    "    nmda_arr = np.array(nmda)\n",
    "    sham_arr = np.array(sham)\n",
    "    return nmda_arr, sham_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VEP_lines(nmda_arr, sham_arr):\n",
    "    mean_nmda = nmda_arr.mean(axis=0)#.mean(axis=0)\n",
    "    mean_sham = sham_arr.mean(axis=0)#.mean(axis=0)\n",
    "\n",
    "    print('Group nmda array: {0}'.format(nmda_arr.shape))\n",
    "    print('Group nmda mean: {0}'.format(mean_nmda.shape))\n",
    "    print('Group sham array: {0}'.format(sham_arr.shape))\n",
    "    print('Group sham mean: {0}'.format(mean_sham.shape))\n",
    "\n",
    "#     V1_nmda = mean_nmda[:, 0:100, :]\n",
    "#     min_nmda = np.where(V1_nmda == np.amin(V1_nmda))\n",
    "#     min_ch_nmda = min_nmda[0][0]\n",
    "#     V1_sham = mean_sham[:, 0:100, :]\n",
    "#     min_sham = np.where(V1_sham == np.amin(V1_sham))\n",
    "#     min_ch_sham = min_sham[0][0]\n",
    "    \n",
    "    min_ch_nmda, min_ch_sham = 65,65\n",
    "    \n",
    "    return mean_nmda, mean_sham, min_ch_nmda, min_ch_sham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_input = input('pre/post/novel: ')\n",
    "\n",
    "\n",
    "if my_input == 'pre':\n",
    "    my_array = all_pre_arr\n",
    "    et_ls = et_ls_pre\n",
    "elif my_input == 'post':\n",
    "    my_array = all_post_arr\n",
    "    et_ls = et_ls_post\n",
    "elif my_input == 'novel':\n",
    "    my_array = all_novel_arr\n",
    "    et_ls = et_ls_novel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmda_arr, sham_arr = split_mice_groups(my_array, et_ls)\n",
    "mean_nmda, mean_sham, min_ch_nmda, min_ch_sham = VEP_lines(nmda_arr, sham_arr)\n",
    "\n",
    "plvdic = []\n",
    "nmda_channel = mean_nmda[:, min_ch_nmda, :]\n",
    "sham_channel = mean_sham[:, min_ch_sham, :]\n",
    "tf,phd = calc_plv(nmda_channel, sham_channel)\n",
    "plvdic.append((tf, phd))\n",
    "\n",
    "tmpdf=pd.DataFrame(plvdic, columns=['plv','phsdiff'])\n",
    "print(tf.shape, phd.shape)\n",
    "tmpdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_idx = [0, 400]\n",
    "min_freq = 2\n",
    "max_freq = 90 #40,50\n",
    "num_frex = 40\n",
    "range_cycles = [3, 10]\n",
    "\n",
    "# data info\n",
    "Sampling_Rate = 2500.\n",
    "num_samples = 7350\n",
    "\n",
    "#frequencies vector\n",
    "frex = np.logspace(np.log10(min_freq),np.log10(max_freq),num_frex)\n",
    "time = np.linspace(0, num_samples, int(num_samples) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot mean VEPs and PLV together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_nmda_trs = mean_nmda.mean(axis=0)\n",
    "mean_sham_trs = mean_sham.mean(axis=0)\n",
    "\n",
    "nmda_mean_ch = 65\n",
    "sham_mean_ch = 65\n",
    "\n",
    "sr=2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(2,1,figsize=(12,4*2))\n",
    "\n",
    "#VEP line plots\n",
    "mean_ch_tracenmda = mean_nmda_trs[nmda_mean_ch,:]\n",
    "time_arr2_nmda = np.linspace(0, mean_ch_tracenmda.shape[0]/sr, mean_ch_tracenmda.shape[0])\n",
    "mean_ch_tracesham = mean_sham_trs[sham_mean_ch,:]\n",
    "time_arr2_sham = np.linspace(0, mean_ch_tracesham.shape[0]/sr, mean_ch_tracesham.shape[0])\n",
    "ax[0].plot(time_arr2_sham, mean_ch_tracesham, label='Sham', color='black')\n",
    "ax[0].plot(time_arr2_nmda, mean_ch_tracenmda, label='NMDA', color='royalblue')\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "ax[0].set_title(my_input)\n",
    "ax[0].set_xlabel('Time (s)')\n",
    "ax[0].set_ylim([-360,210])\n",
    "ax[0].set_yticks([-300,-150,0,150])\n",
    "ax[0].set_xlim([0,3.0])\n",
    "ax[0].set_ylabel('uV')\n",
    "ax[0].axvspan(0.5, 0.7, alpha=0.2, facecolor='grey')\n",
    "\n",
    "\n",
    "# PLV plot\n",
    "all_tmp=np.mean(np.stack(tmpdf.plv.values), axis=0)\n",
    "tf_plot = ax[1].contourf(time, frex, all_tmp, cmap='jet', extend='both', levels=np.linspace(0.,1.0,60))\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].set_xticks(np.arange(0,7500,1250))\n",
    "ax[1].set_xticklabels(np.arange(0,3,0.5))\n",
    "ax[1].set_yticks(np.logspace(np.log10(min_freq),np.log10(max_freq),6))\n",
    "ax[1].set_yticklabels(np.round(np.logspace(np.log10(min_freq),np.log10(max_freq),6)))\n",
    "ax[1].set_title(f'Sham/NMDA PLV: {my_input}')\n",
    "ax[1].axvspan(2500*0.5, 2500*0.7, ec ='black', lw=3, fill=False)\n",
    "ax[1].set_xlabel('Time (s)')\n",
    "ax[1].set_ylabel('Frequency (Hz)')\n",
    "cb_tf = f.add_axes([.92, 0.1, 0.02, 0.35])\n",
    "cb_tf = f.colorbar(tf_plot,cax=cb_tf,ticks=np.arange(0,1.1,0.2))\n",
    "cb_tf.set_label('PLV')\n",
    "\n",
    "sns.despine()\n",
    "# Change the end of this next line with a new file name!!\n",
    "# plt.savefig(r\"C:\\Users\\AChub_Lab\\Desktop\\zimmer94\\PLV_trlbytrl_plots\\nmda_post_PLV.pdf\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
